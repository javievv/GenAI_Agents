{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构建具有上下文感知能力的对话代理\n",
    "\n",
    "## 概述\n",
    "本教程概述了创建一个能够在多次交互中保持上下文的对话代理的过程。我们将使用现代 AI 框架来构建一个能够进行更自然、连贯对话的代理。\n",
    "\n",
    "## 动机\n",
    "许多简单的聊天机器人缺乏保持上下文的能力，导致用户体验脱节且令人沮丧。本教程旨在通过实现一个能够记住并引用对话先前部分的对话代理来解决这个问题，从而提高整体交互质量。\n",
    "\n",
    "## 关键组件\n",
    "1. **语言模型**：生成响应的核心 AI 组件。\n",
    "2. **提示模板**：定义我们对话的结构。\n",
    "3. **历史管理器**：管理对话历史和上下文。\n",
    "4. **消息存储**：存储每个对话会话的消息。\n",
    "\n",
    "## 方法详情\n",
    "\n",
    "### 设置环境\n",
    "首先设置必要的 AI 框架并确保能够访问合适的语言模型。这构成了我们对话代理的基础。\n",
    "\n",
    "### 创建聊天历史存储\n",
    "实现一个系统来管理多个对话会话。每个会话都应具有唯一标识，并与其自己的消息历史相关联。\n",
    "\n",
    "### 定义对话结构\n",
    "创建一个包含以下内容的模板：\n",
    "- 定义 AI 角色的系统消息\n",
    "- 对话历史的占位符\n",
    "- 用户的输入\n",
    "\n",
    "这种结构指导 AI 的响应并在整个对话过程中保持一致性。\n",
    "\n",
    "### 构建对话链\n",
    "将提示模板与语言模型结合以创建一个基本的对话链。将此链包装在历史管理组件中，该组件自动处理对话历史的插入和检索。\n",
    "\n",
    "### 与代理交互\n",
    "要使用该代理，请使用用户输入和会话标识符调用它。历史管理器负责检索适当的对话历史，将其插入提示中，并在每次交互后存储新消息。\n",
    "\n",
    "## 结论\n",
    "这种创建对话代理的方法提供了几个优点：\n",
    "- **上下文感知**：代理可以引用对话的先前部分，从而实现更自然的交互。\n",
    "- **简单性**：模块化设计使实现保持简单。\n",
    "- **灵活性**：易于修改对话结构或切换到不同的语言模型。\n",
    "- **可扩展性**：基于会话的方法允许管理多个独立的对话。\n",
    "\n",
    "有了这个基础，您可以通过以下方式进一步增强代理：\n",
    "- 实现更复杂的提示工程\n",
    "- 将其与外部知识库集成\n",
    "- 为特定领域添加专业能力\n",
    "- 结合错误处理和对话修复策略\n",
    "\n",
    "通过专注于上下文管理，这种对话代理设计显着改进了基本的聊天机器人功能，为更具吸引力和有用的 AI 助手铺平了道路。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 对话代理教程\n",
    "\n",
    "本笔记本演示了如何使用 LangChain 创建一个简单的对话代理。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导入所需的库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -q langchain langchain_experimental openai python-dotenv langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain.memory import ChatMessageHistory\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加载环境变量并初始化语言模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", max_tokens=1000, temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  创建一个简单的内存聊天历史存储\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = {}\n",
    "\n",
    "def get_chat_history(session_id: str):\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建提示模板\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful AI assistant.\"),\n",
    "    MessagesPlaceholder(variable_name=\"history\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 将提示和模型组合成可运行的链\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 用消息历史包装链\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_with_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_chat_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"history\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 示例用法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you. How can I assist you today?\n",
      "AI: Your previous message was, \"Hello! How are you?\" How can I assist you further?\n"
     ]
    }
   ],
   "source": [
    "session_id = \"user_123\"\n",
    "\n",
    "\n",
    "response1 = chain_with_history.invoke(\n",
    "    {\"input\": \"Hello! How are you?\"},\n",
    "    config={\"configurable\": {\"session_id\": session_id}}\n",
    ")\n",
    "print(\"AI:\", response1.content)\n",
    "\n",
    "response2 = chain_with_history.invoke(\n",
    "    {\"input\": \"What was my previous message?\"},\n",
    "    config={\"configurable\": {\"session_id\": session_id}}\n",
    ")\n",
    "print(\"AI:\", response2.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 打印对话历史"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Conversation History:\n",
      "human: Hello! How are you?\n",
      "ai: Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you. How can I assist you today?\n",
      "human: What was my previous message?\n",
      "ai: Your previous message was, \"Hello! How are you?\" How can I assist you further?\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nConversation History:\")\n",
    "for message in store[session_id].messages:\n",
    "    print(f\"{message.type}: {message.content}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}